# -*- coding: utf-8 -*-
"""AI_Lab_Mid.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10v6zHWyDVJePYIP9n-73FdZIbvnfINhd
"""

# 1.	Create 3x3 matrix with random number elements
import numpy as np 
randMat = np.random.randint(0,5,(3,3))
randMat

#2.	Donâ€™t change original array, substitute even numbers in it to -1, such as
 	# a = [11, 12, 13, 14]
	# b = [11, -1, 13, -1]

arr = [11, 12, 13, 14]
for i in range(len(arr)):
  if arr[i]%2 == 0:
    arr[i] = -1
arr

#3 3.	Extract the common elements from two arrays, like
	# a = [11,12, 13, 14] and b = [11,13, 15, 16]
	# c = [11, 13]
a = [11,12, 13, 14] 
b = [11,13, 15, 16]
c = []
for i in range(len(a)):
  if len(a)<=len(b):
    for j in range(len(b)):
      if a[i] == b[j]:
        c.append(a[i])
        continue 
  else: 
     for j in range(len(a)):
      if b[i] == c[j]:
        c.append(a[i])
        continue 
print(c)

# 4.	Swap 2 rows in a 3x3 matrix
# let a be the 
a = np.array([[1,2,3], [3,4,5], [5,6,7]])
print(a)

# swap two raws ( lets swap 1st and 2nd)

a[[0,1]] = a[[1, 0]]
print(a)

# 5.	Calculate mean and standard deviation in an integer array
a = np.array([1, 2, 3, 4, 5, 6, 7])
print(a)
  
mean = np.mean(a)
print("\nMean: ", mean)
  
standarDeviation = np.std(a)
print("\nstandard Deviation: ", standarDeviation)

#6.	Convert string 'P' and 'NP' to number 0 and 1 respectively in a given 1d array, such as 
# a = [1, 2, 3, 'P', 4, 5, 6, 'NP']
# b = [1, 2, 3, 0, 4, 5, 6, 1]
a = [1, 2, 3, 'P', 4, 5, 6, 'NP']
print("a = ",a)
b = []
for i in range(len(a)):
  if a[i] == 'P':
    b.append(0) 
  elif a[i] == "NP":
      b.append(1) 
  else:
      b.append(a[i])
print("b = ", b)

#7.	Plot two lines on one figure with the legend for each
import matplotlib.pyplot as plt 
x= [2, 3, 4, 5, 6, 7, 7, 8]
y1 = [3, 4, 3,6, 7, 5, 6, 8] 
y2 = [4, 5, 4, 7, 8, 6 , 7, 9]

plt. plot(x,y1, label='y1 Graph')
plt.plot(x,y2, label=' y2 Graph')
plt.xlabel('x')
plt.ylabel('y')
plt.title('random graph')
plt.legend()
plt.show()

#8. Draw a 2d scatter plot for samples (X1, X2, y) in different colors for y = 0 and y = 1 
import matplotlib.pyplot as plt 
x1= [2, 3, 4, 5, 6, 7, 7, 8]
x2 = [3, 4, 3,6, 7, 5, 6, 8] 
y = [0, 1, 1, 0, 0, 1 , 1, 0]

plt.scatter(x1, x2 ,c= y) 
plt.xlabel('x1')
plt.ylabel('x2')
plt.title('random graph')
plt.legend()
plt.show()

#9.	Change 1d array from 0 to 8 to 3x3 dataframe(matrix) 
import numpy as np
import pandas as pd
ar1= np.array([0,1,2,3,4,5,6,7,8])
ar2 = np.reshape(ar1, (-1, 3))
numpyData = np.array(ar2)
data_frame = pd.DataFrame(data=numpyData, index=["r1", "r2","r3"], columns=["c1", "c2","c3"])
print(data_frame)

# 10.	Calculate the Euclidean distance from two 1d arrays, such as 
# a = [1, 2, 3] and b = [4, 5, 6]
from numpy.ma.core import sqrt
a = [1, 2, 3]
b = [4, 5, 6]
ec_d = 0
for i in range(len(a)):
   d1 = a[i]
   d2 = b[i]
   ec_d += (d1- d2)**2
ec_d = sqrt(ec_d)
print("Eucludian Distance =", ec_d)

# 11.	Only import odd number rows from a csv file
import numpy as np
import pandas as pd

# loading file from google collab
from google.colab import drive
drive.mount('/content/drive')  
path = ('/content/q11.txt')  # file path

data = pd.read_csv(path) # load data 

data = pd.DataFrame(data[::2]) # read every next line which is 1, 3, 5 ..... etc

#12.	Substitute all elements in diagonals to 0 in a 5x5 dataframe(matrix) 
import numpy as np
import pandas as pd
dataFrame = pd.DataFrame(np.random.rand(5,5))
dataFrame.values[[np.arange(dataFrame.shape[0])]*2] = 0
print(dataFrame)

#13.	Separate a dataframe 80% to trainingset and 20% as testset 
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd

# using the random data from 12 
dataFrame = pd.DataFrame(np.random.rand(5,5))
dataFrame.values[[np.arange(dataFrame.shape[0])]*2] = 0

# dividing data in two x and y 

X = dataFrame.iloc[:, :-1].values         # Assign 1st/2nd/3rd/4th colums values to X
y = dataFrame.iloc[:, 4].values           # Assign 5th column values to y

# dividing the data in to training and testing sets 

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)   # dataframe 80% to trainingset and 20% as testset